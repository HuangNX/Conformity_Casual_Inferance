{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73dd857-6c06-4e0e-9580-fe7595986570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils.evaluation_utils import load_data, save_data\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c82850-f210-41ae-aae9-d17c80e4cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if (col_type != object) or (col_type != Timestamp):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8accce-6710-4bb9-ba88-5c61e650581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8545.41 Mb, 2594.14 Mb (69.64 %)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data_filename = [\"../data/raw_data/conformity_result1_2019_yura_1.csv\", \n",
    "                 \"../data/raw_data/conformity_result1_2020_yura_1.csv\",\n",
    "                 \"../data/raw_data/conformity_result1_2020_yura_2.csv\",\n",
    "                 \"../data/raw_data/conformity_result1_2023_yura_1.csv\",\n",
    "                 \"../data/raw_data/conformity_result1_2023_yura_2.csv\"]\n",
    "\n",
    "data = []\n",
    "for path in data_filename:\n",
    "    per_data = pd.read_csv(path)\n",
    "    \n",
    "    if \"2019\" in path:\n",
    "        year_code = [1,0,0]\n",
    "    elif \"2020\" in path[0]:\n",
    "        year_code = [0,1,0]\n",
    "    elif \"2023\" in path[0]:\n",
    "        year_code = [0,0,1]\n",
    "    per_data[['year_0','year_1','year_2']] = np.tile(year_code, (len(per_data), 1))\n",
    "    data.append(per_data)\n",
    "    del per_data\n",
    "    gc.collect()\n",
    "\n",
    "data = pd.concat(data, axis=0, ignore_index=True)\n",
    "\n",
    "# reduce mem\n",
    "data = reduce_mem(data)\n",
    "gc.collect()\n",
    "data.rename(columns={\"grid_id\":\"pid\", \"weight\":\"dist\", \"sc_250_avg\":\"sci\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4884e107-3123-4687-9093-3c461c00c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sampling\n",
    "sample_id = data['pid'].drop_duplicates().sample(n=10000)\n",
    "data = data[data['pid'].isin(sample_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af4c1d3b-984d-441e-8be5-9c27854b26c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values\n",
    "# 步骤 1: 分组并计算每个组中 'sci' 和 'dist' 的非缺失值数量\n",
    "non_missing_counts = data.groupby('pid')[['sci','dist']].count()\n",
    "# 步骤 2: 找出 'sci' 和 'dist' 都是完全缺失的组\n",
    "groups_to_remove = non_missing_counts[(non_missing_counts['sci'] == 0) | (non_missing_counts['dist'] == 0)].index.get_level_values('pid').unique()\n",
    "# 步骤 3: 生成要删除的行的索引\n",
    "indexes_to_drop = data[data.set_index('pid').index.isin(groups_to_remove)].index\n",
    "data = data.drop(indexes_to_drop)  # 使用 drop 删除这些行\n",
    "# 步骤 4: 使用均值填充缺失值\n",
    "data['sci'] = data.groupby('pid')['sci'].transform(lambda x: x.fillna(x.mean()))\n",
    "data['dist'] = data.groupby('pid')['dist'].transform(lambda x: x.fillna(x.mean()))\n",
    "# step 5: 重新排序\n",
    "data = data.sort_values(by=['pid', 'date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66ef186c-f2d9-4117-b953-694ceda0d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features join\n",
    "# 1.read individual attributes\n",
    "attr = pd.read_csv(\"../data/raw_data/sample_grid_attr_yura_1.csv\")\n",
    "attr.rename(columns = {\"grid_count\":\"pid\", \"grid_g\":\"gender\", \"grid_type\":\"age\"}, inplace=True)\n",
    "be_varis = pd.read_csv(\"../data/raw_data/BE_varis.csv\")\n",
    "#attr = pd.merge(attr, be_varis[['fnid','density','landusemix','road_density','center','subway','edu','married','rent']], on='fnid',how=\"left\")\n",
    "attr = pd.merge(attr, be_varis[['fnid','edu','married','rent']], on='fnid',how=\"left\")\n",
    "# 对没有fnid记录的样本，取全样本均值填充缺失值\n",
    "attr.fillna(attr.mean(), inplace=True)\n",
    "\n",
    "data = pd.merge(data, attr.drop(columns=['date']), on='pid',how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad44a7ff-ffc8-45f3-8e69-ce20a8f68ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. individual travel attributes\n",
    "spatial_ent = pd.read_csv(\"../data/raw_data/sample_poi_month_entro_yura.csv\")\n",
    "spatial_ent.rename(columns={\"grid_id\":\"pid\", \"entropy\":\"spatial_ent\"}, inplace=True)\n",
    "temperal_ent = pd.read_csv(\"../data/raw_data/sample_move_month_entro_yura.csv\")\n",
    "temperal_ent.rename(columns={\"grid_id\":\"pid\", \"entropy\":\"temperal_ent\"}, inplace=True)\n",
    "# merge them\n",
    "data['year_month'] = (data['date']/100).astype('int')\n",
    "data = pd.merge(data, spatial_ent, on=['pid','year_month'], how=\"left\")\n",
    "data = pd.merge(data, temperal_ent, on=['pid','year_month'], how=\"left\")\n",
    "# fill 0\n",
    "data['spatial_ent'] = data['spatial_ent'].fillna(0)\n",
    "data['temperal_ent'] = data['temperal_ent'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a56fcb0-6a4d-459c-9bda-741e8226071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.case data\n",
    "case = pd.read_csv(\"../data/raw_data/case_series.csv\")\n",
    "data = pd.merge(data, case[['date','voluntary']], on=\"date\", how=\"left\")\n",
    "data[\"voluntary\"] = data[\"voluntary\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7f941d8-e903-4f49-901d-758193c38f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.weather data\n",
    "weather = pd.read_csv(\"../data/raw_data/weather_info.csv\")\n",
    "data = pd.merge(data, weather, on=\"date\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9699bb5-1e9a-48cd-bbed-3ff690bf54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features construction\n",
    "data['weekday'] = pd.to_datetime(data['date'].astype(str), format=\"%Y%m%d\").dt.weekday\n",
    "holidays_conditions = (\n",
    "(data['date'].isin([20190101, 20200101])) |\n",
    "(data['date'].between(20190204, 20190210) | data['date'].between(20200124, 20200202)) |\n",
    "(data['date'].between(20190405, 20190407) | data['date'].between(20200404, 20200406) | (data['date'] == 20230405)) |\n",
    "(data['date'].between(20190501, 20190504) | data['date'].between(20200501, 20200505) | data['date'].between(20230429, 20230503)) |\n",
    "(data['date'].between(20230622, 20230624)))\n",
    "\n",
    "data['festivals'] = np.where(holidays_conditions, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f45cb05-d718-47a6-adbe-80157fb01dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy variables (E1 & E2)\n",
    "date_conditions = [\n",
    "    (data['date'].between(20200124, 20200223)),\n",
    "    (data['date'].between(20200224, 20200508)),\n",
    "    #(data['date'].between(20200509, 20201231))\n",
    "]\n",
    "event_columns = ['E1','E2']\n",
    "for col, cond in zip(event_columns, date_conditions):\n",
    "    data[col] = np.where(cond, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f502328-912c-40b3-84d3-4c7e26883e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual attributes binning\n",
    "income_thre = data['rent'].quantile(q=[0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "data['age'] = pd.cut(data['age'], bins=[0, 5, 13, 16, float('inf')], labels=['Young', 'Adult', 'MiddleElder', 'Elder'], right=False)\n",
    "data['gender'] = data['gender'].map({1: 'Male', 2: 'Female'})\n",
    "data['income'] = pd.cut(data['rent'], bins=[0] + list(income_thre)[1:], labels=['Bottom', 'Lower', 'Middle', 'Upper', 'Superior'], right=True, include_lowest=True)\n",
    "\n",
    "# Converting columns to category type with specific levels\n",
    "data['age'] = data['age'].astype('category')\n",
    "data['gender'] = data['gender'].astype('category')\n",
    "data['income'] = pd.Categorical(data['income'], categories=[\"Bottom\", \"Lower\", \"Middle\", \"Upper\", \"Superior\"], ordered=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "ind_attr_cols = ['gender', 'age', 'income']\n",
    "for col in ind_attr_cols:\n",
    "    data[col] = le.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7928dd10-f031-47a0-9c54-ac12c1852925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday one-hot encoding\n",
    "weekday_encoded = pd.get_dummies(data['weekday'], prefix='weekday').astype(int)\n",
    "data = data.drop('weekday', axis=1)\n",
    "data= pd.concat([data, weekday_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bac8dc2d-8793-482a-b275-46d41ab83339",
   "metadata": {},
   "outputs": [],
   "source": [
    " # treatment and outcome - log transformation\n",
    "data['sci'] = np.log(data['sci'] + 1)\n",
    "data['dist'] = np.log(data['dist'] + 1)\n",
    "data['voluntary'] = np.log(data['voluntary'] + 1)\n",
    "\n",
    "# shift获得t-1列（voluntary是否需要t-1）\n",
    "# use yesterday norm_mean as conformity factor\n",
    "data[['sci_yes','dist_yes','voluntary_yes']] = data.groupby('pid')[['sci','dist','voluntary']].shift(1)\n",
    "# delete null in conformity and dist_yes (i.e. delete the first day in every year)\n",
    "data = data.dropna(subset=['sci_yes','dist_yes','voluntary_yes']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1caf584-b14f-4176-abec-8008b3caf5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4880000 entries, 0 to 4879999\n",
      "Data columns (total 33 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   pid            int32  \n",
      " 1   date           int32  \n",
      " 2   dist           float16\n",
      " 3   sci            float32\n",
      " 4   year_0         int8   \n",
      " 5   year_1         int8   \n",
      " 6   year_2         int8   \n",
      " 7   gender         int64  \n",
      " 8   age            int64  \n",
      " 9   fnid           float64\n",
      " 10  edu            float64\n",
      " 11  married        float64\n",
      " 12  rent           float64\n",
      " 13  year_month     int64  \n",
      " 14  spatial_ent    float64\n",
      " 15  temperal_ent   float64\n",
      " 16  voluntary      float64\n",
      " 17  temperature    float64\n",
      " 18  percipit       float64\n",
      " 19  festivals      int64  \n",
      " 20  E1             int64  \n",
      " 21  E2             int64  \n",
      " 22  income         int64  \n",
      " 23  weekday_0      int64  \n",
      " 24  weekday_1      int64  \n",
      " 25  weekday_2      int64  \n",
      " 26  weekday_3      int64  \n",
      " 27  weekday_4      int64  \n",
      " 28  weekday_5      int64  \n",
      " 29  weekday_6      int64  \n",
      " 30  sci_yes        float32\n",
      " 31  dist_yes       float16\n",
      " 32  voluntary_yes  float64\n",
      "dtypes: float16(2), float32(2), float64(10), int32(2), int64(14), int8(3)\n",
      "memory usage: 1000.6 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ef76e7a-350e-4fc6-9a2d-f80dc4e02329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>date</th>\n",
       "      <th>dist</th>\n",
       "      <th>sci</th>\n",
       "      <th>year_0</th>\n",
       "      <th>year_1</th>\n",
       "      <th>year_2</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>fnid</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_5</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>sci_yes</th>\n",
       "      <th>dist_yes</th>\n",
       "      <th>voluntary_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12023</td>\n",
       "      <td>20190102</td>\n",
       "      <td>2.017578</td>\n",
       "      <td>4.242451</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25498.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.425946</td>\n",
       "      <td>2.244141</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12023</td>\n",
       "      <td>20190103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.956927</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25498.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.242451</td>\n",
       "      <td>2.017578</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12023</td>\n",
       "      <td>20190104</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.206891</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25498.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.956927</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12023</td>\n",
       "      <td>20190105</td>\n",
       "      <td>2.671875</td>\n",
       "      <td>5.529972</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25498.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.206891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12023</td>\n",
       "      <td>20190106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.490638</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25498.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.529972</td>\n",
       "      <td>2.671875</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pid      date      dist       sci  year_0  year_1  year_2  gender  age  \\\n",
       "0  12023  20190102  2.017578  4.242451       1       0       0       0    0   \n",
       "1  12023  20190103  0.000000  7.956927       1       0       0       0    0   \n",
       "2  12023  20190104  0.000000  7.206891       1       0       0       0    0   \n",
       "3  12023  20190105  2.671875  5.529972       1       0       0       0    0   \n",
       "4  12023  20190106  0.000000  5.490638       1       0       0       0    0   \n",
       "\n",
       "      fnid  ...  weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  \\\n",
       "0  25498.0  ...          0          0          1          0          0   \n",
       "1  25498.0  ...          0          0          0          1          0   \n",
       "2  25498.0  ...          0          0          0          0          1   \n",
       "3  25498.0  ...          0          0          0          0          0   \n",
       "4  25498.0  ...          0          0          0          0          0   \n",
       "\n",
       "   weekday_5  weekday_6   sci_yes  dist_yes  voluntary_yes  \n",
       "0          0          0  7.425946  2.244141            0.0  \n",
       "1          0          0  4.242451  2.017578            0.0  \n",
       "2          0          0  7.956927  0.000000            0.0  \n",
       "3          1          0  7.206891  0.000000            0.0  \n",
       "4          0          1  5.529972  2.671875            0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8431fc6-5a59-4786-87ae-c9356cb8bdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"../data/sample_1w_dataframe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbb3fa68-54cc-468c-a7dd-50766b2d44a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grid_id</th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>month_duration</th>\n",
       "      <th>month_ltime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69566445</td>\n",
       "      <td>20230801</td>\n",
       "      <td>98993</td>\n",
       "      <td>8240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69564867</td>\n",
       "      <td>20230801</td>\n",
       "      <td>57113</td>\n",
       "      <td>129749981.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69563436</td>\n",
       "      <td>20230501</td>\n",
       "      <td>31624</td>\n",
       "      <td>267612265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69561851</td>\n",
       "      <td>20190401</td>\n",
       "      <td>37140</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69561658</td>\n",
       "      <td>20230801</td>\n",
       "      <td>8408</td>\n",
       "      <td>345302597.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    grid_id  yearmonth  month_duration  month_ltime\n",
       "0  69566445   20230801           98993       8240.0\n",
       "1  69564867   20230801           57113  129749981.0\n",
       "2  69563436   20230501           31624  267612265.0\n",
       "3  69561851   20190401           37140          NaN\n",
       "4  69561658   20230801            8408  345302597.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/raw_data/sample_mobile_flow_rango.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848a6d24-6f90-40b5-80ea-a95ca2153218",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['month_ltime'] = data['month_ltime'].fillna(0)\n",
    "data['flow'] = data['month_ltime'] / data['month_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf48a495-b839-4221-a354-0c3539d08c28",
   "metadata": {},
   "source": [
    "## 数据集处理\n",
    "1. 删掉多余的建成环境指标\n",
    "2. 生成三年的数据，其中treatment只有sci，policy作为协变量\n",
    "3. 提取出20年单独的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "489d2945-d77a-4b88-8867-cb0e520bb99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariates\n",
      "(981651, 161, 23)\n",
      "float32\n",
      "outcomes\n",
      "(981651, 161, 1)\n",
      "float32\n",
      "sequence_length\n",
      "(981651,)\n",
      "int64\n",
      "treatments\n",
      "(981651, 161, 1)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "dataset = load_data(\"../data/sample_32w.h5\")\n",
    "\n",
    "for key in dataset.keys():\n",
    "    print(key)\n",
    "    print(dataset[key].shape)\n",
    "    print(dataset[key].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71707896-ce3a-4489-8d12-c329772358cc",
   "metadata": {},
   "source": [
    "原始的covariate列\n",
    "['gender','age','income','weekday_0','weekday_1','weekday_2','weekday_3','weekday_4', 'weekday_5', 'weekday_6',\n",
    "                'voluntary','festivals','year_0','year_1','year_2','density','landusemix','road_density','center','subway','edu',\n",
    "                'married','dist_yes','temperature','percipit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3731f0b-c90d-4717-b07c-ca22b767e98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariates\n",
      "(981651, 161, 21)\n",
      "float32\n",
      "outcomes\n",
      "(981651, 161, 1)\n",
      "float32\n",
      "previous_covariates\n",
      "(981651, 160, 21)\n",
      "float32\n",
      "previous_treatments\n",
      "(981651, 160, 3)\n",
      "float32\n",
      "sequence_length\n",
      "(981651,)\n",
      "int64\n",
      "treatments\n",
      "(981651, 161, 3)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "# 列表中 'landusemix', 'road_density', 'center', 'subway' 的索引\n",
    "columns_to_remove = [16, 17, 18, 19]  # 以0为起始索引\n",
    "\n",
    "# 删除 covariates 中的指定列\n",
    "dataset['covariates'] = np.delete(dataset['covariates'], columns_to_remove, axis=2)\n",
    "\n",
    "# 删除 previous_covariates 中的指定列\n",
    "dataset['previous_covariates'] = np.delete(dataset['previous_covariates'], columns_to_remove, axis=2)\n",
    "\n",
    "for key in dataset.keys():\n",
    "    print(key)\n",
    "    print(dataset[key].shape)\n",
    "    print(dataset[key].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be1456f-bfa7-4b07-9c9c-88bb7d10a0e0",
   "metadata": {},
   "source": [
    "此时的covariate列\n",
    "['gender','age','income','weekday_0','weekday_1','weekday_2','weekday_3','weekday_4', 'weekday_5', 'weekday_6',\n",
    "                'voluntary','festivals','year_0','year_1','year_2','density','edu',\n",
    "                'married','dist_yes','temperature','percipit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c97b167-164a-4376-b254-bf8914aad499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取出2020年单独的数据，生成2020data\n",
    "def obtain_dataset(dataset, column_index, selection=1):\n",
    "    dataset_part = {}\n",
    "    selected_indices = np.where(dataset['covariates'][:, :, column_index] == selection)[0]\n",
    "    unique_selected_indices = np.unique(selected_indices)\n",
    "    for key in dataset.keys():\n",
    "        dataset_part[key] = dataset[key][unique_selected_indices]\n",
    "    return dataset_part\n",
    "\n",
    "column_2020 = 13  # index of year 2020 indicator\n",
    "dataset20 = obtain_dataset(dataset, column_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edc6be12-a795-4daf-b382-c787bda72253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariates\n",
      "(981651, 161, 23)\n",
      "float32\n",
      "outcomes\n",
      "(981651, 161, 1)\n",
      "float32\n",
      "previous_covariates\n",
      "(981651, 160, 21)\n",
      "float32\n",
      "previous_treatments\n",
      "(981651, 160, 3)\n",
      "float32\n",
      "sequence_length\n",
      "(981651,)\n",
      "int64\n",
      "treatments\n",
      "(981651, 161, 1)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "# 将政策变量加入covariate和previous_covariates\n",
    "policy_columns = dataset['treatments'][:, :, -2:]\n",
    "\n",
    "# 将这两列合并到 covariates 的最后\n",
    "dataset['covariates'] = np.concatenate((dataset['covariates'], policy_columns), axis=2)\n",
    "\n",
    "# 从 treatments 删除最后两列\n",
    "dataset['treatments'] = dataset['treatments'][:, :, :-2]\n",
    "\n",
    "for key in dataset.keys():\n",
    "    print(key)\n",
    "    print(dataset[key].shape)\n",
    "    print(dataset[key].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e6187-0f69-4860-a1ae-a5df48ba2644",
   "metadata": {},
   "source": [
    "此时的covariate列 ['gender','age','income','weekday_0','weekday_1','weekday_2','weekday_3','weekday_4', 'weekday_5', 'weekday_6', 'voluntary','festivals','year_0','year_1','year_2','density','edu', 'married','dist_yes','temperature','percipit', 'policy_1', 'policy_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "118b09bd-6af4-4450-b621-5a6bef7b61bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariates\n",
      "(981651, 161, 23)\n",
      "float32\n",
      "outcomes\n",
      "(981651, 161, 1)\n",
      "float32\n",
      "sequence_length\n",
      "(981651,)\n",
      "int64\n",
      "treatments\n",
      "(981651, 161, 1)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "# 删除 previous_treatments 键和其数据\n",
    "if 'previous_treatments' in dataset:\n",
    "    del dataset['previous_treatments']\n",
    "\n",
    "# 删除 previous_covariates 键和其数据\n",
    "if 'previous_covariates' in dataset:\n",
    "    del dataset['previous_covariates']\n",
    "\n",
    "for key in dataset.keys():\n",
    "    print(key)\n",
    "    print(dataset[key].shape)\n",
    "    print(dataset[key].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eea611f-6701-458c-9dff-6ac880558dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish ../data/sample_32w_2020.h5!\n",
      "Finish ../data/sample_32w.h5!\n"
     ]
    }
   ],
   "source": [
    "# 保存生成的dataset20数据\n",
    "save_data('../data/sample_32w_2020.h5', dataset20)\n",
    "\n",
    "# 保存新的dataset\n",
    "save_data('../data/sample_32w.h5', dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d6146a-4d92-4000-bc90-8cd501784636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.        ]\n",
      "  [ 0.2186165 ]\n",
      "  [ 0.24198702]\n",
      "  ...\n",
      "  [ 0.60612154]\n",
      "  [ 0.61547446]\n",
      "  [ 0.64035958]]\n",
      "\n",
      " [[ 1.        ]\n",
      "  [ 0.39805797]\n",
      "  [ 0.71758068]\n",
      "  ...\n",
      "  [ 0.38854495]\n",
      "  [ 0.61221683]\n",
      "  [ 4.38675785]]\n",
      "\n",
      " [[ 1.        ]\n",
      "  [ 2.76691246]\n",
      "  [ 0.78857583]\n",
      "  ...\n",
      "  [ 0.36140603]\n",
      "  [ 0.2374164 ]\n",
      "  [ 0.29409248]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.        ]\n",
      "  [ 0.48634303]\n",
      "  [ 4.63589239]\n",
      "  ...\n",
      "  [42.00141525]\n",
      "  [ 2.19222713]\n",
      "  [20.19682884]]\n",
      "\n",
      " [[ 1.        ]\n",
      "  [ 1.60044539]\n",
      "  [ 2.99170256]\n",
      "  ...\n",
      "  [ 2.70778584]\n",
      "  [ 0.38779899]\n",
      "  [ 9.78914738]]\n",
      "\n",
      " [[ 1.        ]\n",
      "  [ 0.17965211]\n",
      "  [ 0.1899278 ]\n",
      "  ...\n",
      "  [ 0.23001415]\n",
      "  [ 0.25791985]\n",
      "  [ 0.26360363]]]\n"
     ]
    }
   ],
   "source": [
    "ps = np.load(\"results/rmsn_all_data_no_deconfound_use_confounders_False/propensity_scores.npy\")\n",
    "print(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8294d1-b033-489e-9dd9-7859fa450e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariates\n",
      "(327217, 161, 21)\n",
      "float32\n",
      "outcomes\n",
      "(327217, 161, 1)\n",
      "float32\n",
      "previous_covariates\n",
      "(327217, 160, 21)\n",
      "float32\n",
      "previous_treatments\n",
      "(327217, 160, 3)\n",
      "float32\n",
      "sequence_length\n",
      "(327217,)\n",
      "int64\n",
      "treatments\n",
      "(327217, 161, 3)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "dataset20 = load_data(\"../data/sample_32w_2020.h5\")\n",
    "for key in dataset20.keys():\n",
    "    print(key)\n",
    "    print(dataset20[key].shape)\n",
    "    print(dataset20[key].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d8170d-f9cd-43ad-a618-b35d44322230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_causal",
   "language": "python",
   "name": "new_causal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
